"""
CTC Lossë¥¼ ì‚¬ìš©í•œ OCR ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ.

ì´ ëª¨ë“ˆì€ OCR í•™ìŠµì„ ìœ„í•œ CNN-RNN ì•„í‚¤í…ì²˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:
- íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ CNN ë°±ë³¸
- ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì„ ìœ„í•œ ì–‘ë°©í–¥ GRU
- ê°€ë³€ ê¸¸ì´ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ„í•œ CTC ì†ì‹¤ í•¨ìˆ˜

í•™ìŠµ íŒŒì´í”„ë¼ì¸ í¬í•¨ ì‚¬í•­:
- ë°ì´í„° ì¦ê°•
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
- ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- ì¡°ê¸° ì¢…ë£Œ (Early Stopping)
"""

import os
import string
from typing import Optional, Tuple, List

import numpy as np
import pandas as pd
import cv2
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

from .config import ModelConfig, DEFAULT_CONFIG


class CaptchaDataset(Dataset):
    """CAPTCHA ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” ë°ì´í„°ì…‹ í´ë˜ìŠ¤."""
    
    def __init__(
        self,
        csv_path: str,
        image_dir: str,
        config: ModelConfig = None,
        augment: bool = True
    ):
        """
        Args:
            csv_path: [filename, label] ì»¬ëŸ¼ì´ í¬í•¨ëœ CSV íŒŒì¼ ê²½ë¡œ
            image_dir: ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
            config: ëª¨ë¸ ì„¤ì •
            augment: ë°ì´í„° ì¦ê°• ì ìš© ì—¬ë¶€
        """
        self.config = config or DEFAULT_CONFIG
        self.image_dir = image_dir
        self.augment = augment
        
        # ë¼ë²¨ ë¡œë“œ
        self.df = pd.read_csv(csv_path)
        self.df = self.df.dropna(subset=['label'])
        
        # ì´ë¯¸ì§€ ë³€í™˜
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])
    
    def __len__(self) -> int:
        return len(self.df)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:
        row = self.df.iloc[idx]
        img_path = os.path.join(self.image_dir, row['filename'])
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
        
        # ì „ì²˜ë¦¬ ì ìš©
        img = cv2.GaussianBlur(img, (3, 3), 0)
        _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)
        
        # í¬ê¸° ì¡°ì •
        img = cv2.resize(img, (self.config.img_width, self.config.img_height))
        
        # ë³€í™˜ ì ìš©
        img = self.transform(img)
        
        # ë¼ë²¨ ì¸ì½”ë”©
        label_str = str(row['label']).upper()
        label = [self.config.char_to_idx[c] for c in label_str if c in self.config.char_to_idx]
        
        return img, torch.tensor(label, dtype=torch.long), len(label)


class OCRModel(nn.Module):
    """
    CTC ì¶œë ¥ì„ ì‚¬ìš©í•˜ëŠ” CNN-RNN OCR ëª¨ë¸.
    
    ì•„í‚¤í…ì²˜:
        - MaxPoolingì„ í¬í•¨í•œ 2ê°œì˜ Conv ë ˆì´ì–´
        - ì–‘ë°©í–¥ GRU
        - ì™„ì „ ì—°ê²°(Fully Connected) ì¶œë ¥ ë ˆì´ì–´
    """
    
    def __init__(self, config: ModelConfig = None):
        super().__init__()
        self.config = config or DEFAULT_CONFIG
        
        # CNN backbone
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=(2, 2)),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=(2, 1))
        )
        
        # Calculate CNN output dimensions
        conv_output_h = self.config.img_height // 2 // 2
        gru_input_size = 64 * conv_output_h
        
        # RNN layers
        self.gru = nn.GRU(
            input_size=gru_input_size,
            hidden_size=128,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.2
        )
        
        # Output layer
        self.fc = nn.Linear(256, self.config.num_classes)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ìˆœì „íŒŒ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            x: (batch, 1, height, width) í˜•íƒœì˜ ì…ë ¥ í…ì„œ
            
        Returns:
            (time_steps, batch, num_classes) í˜•íƒœì˜ ì¶œë ¥ í…ì„œ
        """
        batch_size = x.size(0)
        
        # CNN íŠ¹ì§• ì¶”ì¶œ
        x = self.cnn(x)
        
        # RNNì„ ìœ„í•œ ë³€í™˜: (batch, width, height*channels)
        x = x.permute(0, 3, 1, 2)  # (batch, width, channels, height)
        x = x.contiguous().view(batch_size, x.size(1), -1)
        
        # RNN ì‹œí€€ìŠ¤ ëª¨ë¸ë§
        x, _ = self.gru(x)
        
        # ì¶œë ¥ íˆ¬ì˜(Projection)
        x = self.fc(x)
        
        # CTC ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìœ„í•œ ë³€í™˜: (time_steps, batch, num_classes)
        x = x.permute(1, 0, 2)
        
        return x


class OCRTrainer:
    """
    CTC ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ OCR ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ í´ë˜ìŠ¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
        - ìë™ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        - í•™ìŠµ ì§„í–‰ë¥  ì‹œê°í™”
        - ì¡°ê¸° ì¢…ë£Œ ì§€ì›
        - ONNX í¬ë§· ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
    """
    
    def __init__(
        self,
        config: ModelConfig = None,
        device: str = None
    ):
        self.config = config or DEFAULT_CONFIG
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        
        self.model = OCRModel(self.config).to(self.device)
        self.criterion = nn.CTCLoss(blank=0, zero_infinity=True)
        self.optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=self.config.learning_rate
        )
    
    def train(
        self,
        train_loader: DataLoader,
        epochs: int = None,
        save_path: str = None
    ) -> List[float]:
        """
        ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            train_loader: í•™ìŠµ ë°ì´í„° ë¡œë”
            epochs: í•™ìŠµ ì—í­ ìˆ˜
            save_path: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
            
        Returns:
            ì—í­ë³„ í•™ìŠµ ì†ì‹¤(Loss) ë¦¬ìŠ¤íŠ¸
        """
        epochs = epochs or self.config.epochs
        save_path = save_path or "weights/ocr_checkpoint.pth"
        
        if len(train_loader) == 0:
            print("âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. labeling_toolì„ ì´ìš©í•´ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
            return []
        
        losses = []
        best_loss = float('inf')
        
        for epoch in range(epochs):
            self.model.train()
            epoch_loss = 0.0
            
            for batch_idx, (images, labels, label_lens) in enumerate(train_loader):
                images = images.to(self.device)
                
                # ìˆœì „íŒŒ
                outputs = self.model(images)
                
                # CTC ì†ì‹¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¤€ë¹„
                input_lens = torch.full(
                    (images.size(0),),
                    outputs.size(0),
                    dtype=torch.long
                )
                
                # ë¼ë²¨ ê²°í•©
                labels_concat = torch.cat(labels).to(self.device)
                label_lens = torch.tensor(label_lens, dtype=torch.long)
                
                # ì†ì‹¤ ê³„ì‚°
                loss = self.criterion(outputs, labels_concat, input_lens, label_lens)
                
                # ì—­ì „íŒŒ
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(train_loader)
            losses.append(avg_loss)
            
            print(f"ğŸ“˜ Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}")
            
            # ìµœìš°ìˆ˜ ëª¨ë¸ ì €ì¥
            if avg_loss < best_loss:
                best_loss = avg_loss
                self.save_checkpoint(save_path)
        
        return losses
    
    def save_checkpoint(self, path: str) -> None:
        """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        os.makedirs(os.path.dirname(path) or '.', exist_ok=True)
        torch.save(self.model.state_dict(), path)
        print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load_checkpoint(self, path: str) -> None:
        """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        self.model.load_state_dict(
            torch.load(path, map_location=self.device)
        )
        print(f"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {path}")
    
    def export_onnx(self, output_path: str) -> None:
        """ëª¨ë¸ì„ ONNX í¬ë§·ìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤."""
        self.model.eval()
        
        # ë”ë¯¸ ì…ë ¥ ìƒì„±
        dummy_input = torch.randn(
            1, 1,
            self.config.img_height,
            self.config.img_width
        ).to(self.device)
        
        # ë‚´ë³´ë‚´ê¸° ìˆ˜í–‰
        torch.onnx.export(
            self.model,
            dummy_input,
            output_path,
            input_names=['image'],
            output_names=['output'],
            dynamic_axes={
                'image': {0: 'batch_size'},
                'output': {1: 'batch_size'}
            },
            opset_version=13
        )
        
        print(f"âœ… ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path}")


def collate_fn(batch):
    """ê°€ë³€ ê¸¸ì´ ë¼ë²¨ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì»¤ìŠ¤í…€ collate í•¨ìˆ˜."""
    images, labels, label_lens = zip(*batch)
    return torch.stack(images), labels, label_lens


if __name__ == "__main__":
    # Example training script
    print("ğŸš€ Starting OCR training...")
    
    config = ModelConfig()
    trainer = OCRTrainer(config)
    
    # Load dataset
    dataset = CaptchaDataset(
        csv_path="data/labels.csv",
        image_dir="data/labeled",
        config=config
    )
    
    loader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=True,
        collate_fn=collate_fn
    )
    
    # Train
    losses = trainer.train(loader, epochs=config.epochs)
    
    # Export to ONNX
    trainer.export_onnx("weights/captcha_model.onnx")
    
    print("âœ… Training completed!")
