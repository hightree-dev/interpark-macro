"""ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•œ ONNX ëŸ°íƒ€ì„ ê¸°ë°˜ CAPTCHA ì˜ˆì¸¡ ëª¨ë“ˆ."""

import os
import time
from typing import Tuple, Optional, Union

import numpy as np
import onnxruntime as ort

from .config import ModelConfig, DEFAULT_CONFIG
from .preprocessor import ImagePreprocessor


class CaptchaPredictor:
    """
    ONNX ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ CAPTCHA ì¸ì‹ í´ë˜ìŠ¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
        - ONNX ìµœì í™” ì¶”ë¡ 
        - ê°€ë³€ ê¸¸ì´ í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ CTC ë””ì½”ë”©
        - ë‹¤ì–‘í•œ ì…ë ¥ í¬ë§· ì§€ì› (ë°”ì´íŠ¸, ê²½ë¡œ, ë„˜íŒŒì´)
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> predictor = CaptchaPredictor("weights/captcha_model.onnx")
        >>> text = predictor.predict(image_bytes)
        >>> print(f"Predicted: {text}")
    """
    
    def __init__(
        self,
        model_path: str = None,
        config: ModelConfig = None
    ):
        """
        CAPTCHA ì˜ˆì¸¡ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            config: ëª¨ë¸ ì„¤ì •
        """
        self.config = config or DEFAULT_CONFIG
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
        if model_path:
            self.model_path = model_path
        else:
            # captcha_ocr/predictor.py ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ weights í´ë” ì°¸ì¡°
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            self.model_path = os.path.join(base_dir, self.config.model_path)
            
        self.preprocessor = ImagePreprocessor(self.config)
        self.session: Optional[ort.InferenceSession] = None
        
        self._load_model()
    
    def _load_model(self) -> None:
        """ONNX ëª¨ë¸ì„ ì„¸ì…˜ì— ë¡œë“œí•©ë‹ˆë‹¤."""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        # í˜¸í™˜ì„±ì„ ìœ„í•´ CPU ì‹¤í–‰ í”„ë¡œë°”ì´ë” ì‚¬ìš©
        self.session = ort.InferenceSession(
            self.model_path,
            providers=['CPUExecutionProvider']
        )
        
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
    
    def _ctc_decode(self, predictions: np.ndarray) -> str:
        """
        Greedy ë””ì½”ë”©ì„ ì‚¬ìš©í•˜ì—¬ CTC ì¶œë ¥ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            predictions: (time_steps, batch, num_classes) í˜•íƒœì˜ ëª¨ë¸ ì¶œë ¥
            
        Returns:
            ë””ì½”ë”©ëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        # Argmax ì˜ˆì¸¡ ì¸ë±ìŠ¤ ì¶”ì¶œ
        pred_indices = np.argmax(predictions, axis=-1)
        
        # ì¶œë ¥ í˜•íƒœ ì²˜ë¦¬
        if len(pred_indices.shape) == 2:
            pred_indices = pred_indices[0]  # ì²« ë²ˆì§¸ ë°°ì¹˜ ì•„ì´í…œ ì‚¬ìš©
        
        # ì¤‘ë³µ ì œê±° ë° ê³µë°± í† í° ì œê±° ë””ì½”ë”©
        decoded = []
        prev_idx = -1
        
        for idx in pred_indices:
            if idx != prev_idx and idx != 0:  # 0ì€ ê³µë°±(blank) í† í°
                char = self.config.idx_to_char.get(idx, '')
                if char:
                    decoded.append(char)
            prev_idx = idx
        
        return ''.join(decoded)[:self.config.max_length]
    
    def predict(
        self,
        image: Union[bytes, str, np.ndarray],
        measure_time: bool = False
    ) -> str:
        """
        ì´ë¯¸ì§€ì—ì„œ CAPTCHA í…ìŠ¤íŠ¸ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            image: ë°”ì´íŠ¸, íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœì˜ ì´ë¯¸ì§€
            measure_time: Trueì¼ ê²½ìš° ì¶”ë¡  ì‹œê°„ ì¶œë ¥
            
        Returns:
            ì˜ˆì¸¡ëœ CAPTCHA í…ìŠ¤íŠ¸
        """
        start_time = time.time() if measure_time else None
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_input = self.preprocessor.preprocess(image)
        
        # ì¶”ë¡  ì‹¤í–‰
        predictions = self.session.run(
            [self.output_name],
            {self.input_name: img_input}
        )[0]
        
        # ê²°ê³¼ ë””ì½”ë”©
        text = self._ctc_decode(predictions)
        
        if measure_time:
            elapsed = time.time() - start_time
            print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {elapsed:.4f}s")
        
        return text
    
    def predict_with_confidence(
        self,
        image: Union[bytes, str, np.ndarray]
    ) -> Tuple[str, float]:
        """
        ì‹ ë¢°ë„ ì ìˆ˜ì™€ í•¨ê»˜ CAPTCHA í…ìŠ¤íŠ¸ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            image: ë°”ì´íŠ¸, íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœì˜ ì´ë¯¸ì§€
            
        Returns:
            (ì˜ˆì¸¡ í…ìŠ¤íŠ¸, ì‹ ë¢°ë„ ì ìˆ˜) íŠœí”Œ
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_input = self.preprocessor.preprocess(image)
        
        # ì¶”ë¡  ì‹¤í–‰
        predictions = self.session.run(
            [self.output_name],
            {self.input_name: img_input}
        )[0]
        
        # Softmax ì ìš©í•˜ì—¬ í™•ë¥  ê³„ì‚°
        probs = self._softmax(predictions)
        
        # ìµœëŒ€ í™•ë¥ ì˜ í‰ê· ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        max_probs = np.max(probs, axis=-1)
        confidence = float(np.mean(max_probs))
        
        # ê²°ê³¼ ë””ì½”ë”©
        text = self._ctc_decode(predictions)
        
        return text, confidence
    
    @staticmethod
    def _softmax(x: np.ndarray) -> np.ndarray:
        """ì…ë ¥ ë°°ì—´ì— Softmaxë¥¼ ì ìš©í•©ë‹ˆë‹¤."""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)


# CLI interface
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python predictor.py <image_path>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    model_path = sys.argv[2] if len(sys.argv) > 2 else "weights/captcha_model.onnx"
    
    try:
        predictor = CaptchaPredictor(model_path)
        result = predictor.predict(image_path, measure_time=True)
        print(f"ğŸ§  Prediction: {result}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)
